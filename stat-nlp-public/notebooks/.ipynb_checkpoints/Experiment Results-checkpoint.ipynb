{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import (DistilBertForSequenceClassification, \n",
    "                          DistilBertTokenizer,\n",
    "                          BertForSequenceClassification,\n",
    "                          BertTokenizer)\n",
    "\n",
    "# Our code imports\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', 'src'))\n",
    "import train_eval\n",
    "import synonym\n",
    "\n",
    "importlib.reload(synonym)\n",
    "importlib.reload(train_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'yelp'\n",
    "imdb = train_eval.ReviewDataset(source=dataset)\n",
    "test_sentences, test_labels = imdb.reviewsAndLabels(test_train=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pretrained_weights = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_pretrained_weights)\n",
    "\n",
    "distil_pretrained_weights = 'distilbert-base-cased'\n",
    "distil_tokenizer = DistilBertTokenizer.from_pretrained(distil_pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments 1.1 - 1.2 and 2.1 - 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the local (attack training) model - which we'll be using to identify misclassified reviews \n",
    "model_path = 'imdb_bert.model'\n",
    "model = torch.load(model_path)\n",
    "\n",
    "# set up the target models (the one's we're trying to show we can fool by assuming we can transfer \n",
    "# successful attacks from our local model)\n",
    "target_models = ['yelp_distil.model', 'yelp_bert.model']\n",
    "\n",
    "bert_pretrained_weights = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_pretrained_weights)\n",
    "\n",
    "distil_pretrained_weights = 'distilbert-base-cased'\n",
    "distil_tokenizer = DistilBertTokenizer.from_pretrained(distil_pretrained_weights)\n",
    "\n",
    "# set up the reviews we are evaluating on\n",
    "dataset = 'yelp'\n",
    "yelp = train_eval.ReviewDataset(source=dataset, number_reviews=50)\n",
    "test_sentences, test_labels = yelp.reviewsAndLabels(test_train=\"train\")\n",
    "\n",
    "# the pre-computed hot-word distribution\n",
    "vocab, word_weights, word_sorts = pickle.load(open(\"bert-vcb_wt_sort.p\", \"rb\"))\n",
    "word_dist = dict(zip(vocab, word_weights))\n",
    "\n",
    "# set up hyperparameters\n",
    "gamma = 80\n",
    "methods = ['hot_word', 'random']\n",
    "\n",
    "# set up outputs and intermediate values\n",
    "accuracies = []\n",
    "no_reviews = dict()\n",
    "output = dict()\n",
    "non_adv_output = dict()\n",
    "\n",
    "# instantiate attack class\n",
    "s_attacks = synonym.SynonymAttacks(model_path, bert_tokenizer, 256)\n",
    "\n",
    "for method in methods:\n",
    "    # we'll do it for both the hot word and random methods\n",
    "\n",
    "    # here we generate the adversarial sentences (i.e., with synonyms replaced) \n",
    "    # and labels (ground truth)\n",
    "    adv_reviews, adv_label = s_attacks.generateSynonymReviews(test_sentences, test_labels,\n",
    "                                                           replacements=gamma, \n",
    "                                                           hot_word_distribution=word_dist,\n",
    "                                                           method=method)\n",
    "    \n",
    "    # set up data is a convenience static method, to create a pytorch dataset object\n",
    "    evaluation_data, _ = train_eval.ReviewDataset.setUpData(adv_reviews, \n",
    "                                                            adv_label, \n",
    "                                                            tokenizer, 256, split=\"no_shuffle\")\n",
    "    \n",
    "    # run the evaluation loop using the fine-tuned model, to identify misclassified reviews\n",
    "    _, pred_labels, _, _, true_labels= train_eval.evaluate(model, \n",
    "                                                           evaluation_data, \n",
    "                                                           batch_size=20,\n",
    "                                                           return_pred_labels=True)\n",
    "    \n",
    "    # flatten and find misclassified reviews\n",
    "    pred = np.array([q for p in pred_labels for q in p]) \n",
    "    true = np.array([q for p in true_labels for q in p])\n",
    "    m = np.where(pred!=true)\n",
    "\n",
    "    no_reviews[method] = len(m[0])\n",
    "\n",
    "    # return the ids, true labels and attention masks of the MISCLASSIFIED reviews\n",
    "    true_flat = true[m]\n",
    "\n",
    "    # recover the misclassified reviews, and set up to attack target model\n",
    "    attack_reviews = adv_reviews[m]\n",
    "\n",
    "    # for comparison, the same reviews without an adversarial attack\n",
    "    non_attack_reviews = test_sentences\n",
    "\n",
    "    # evaluate the accuracy on the target models (both yelp trained Bert and DistilBert)\n",
    "    for target in target_models:\n",
    "        if \"distil\" in target:\n",
    "            target_tokenizer = distil_tokenizer\n",
    "        elif \"bert\" in target:\n",
    "            target_tokenizer = bert_tokenizer\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # static method to create pytorch dataset object\n",
    "        model_input, _ = train_eval.ReviewDataset.setUpData(attack_reviews,\n",
    "                                                            true_flat,\n",
    "                                                            target_tokenizer)\n",
    "        non_adv_model_input, _ = train_eval.ReviewDataset.setUpData(non_attack_reviews,\n",
    "                                                                    true,\n",
    "                                                                    target_tokenizer)\n",
    "\n",
    "        # load the fine-tuned target model\n",
    "        loaded_target_model = torch.load(target)\n",
    "\n",
    "        # evaluate on the target data, and return the accuracies\n",
    "        adv_accuracies, _, _, _, _ = train_eval.evaluate(loaded_target_model, \n",
    "                                                         model_input, \n",
    "                                                         batch_size=20)\n",
    "        \n",
    "        # for comparison, run on the original test data\n",
    "        non_adv_accuracies, _, _, _, _ = train_eval.evaluate(loaded_target_model, \n",
    "                                                             non_adv_model_input, \n",
    "                                                             batch_size=20)\n",
    "    \n",
    "        # get the average accuracy across the batches\n",
    "        accuracy = np.mean(adv_accuracies)\n",
    "        non_adv_accuracy = np.mean(non_adv_accuracies)\n",
    "\n",
    "        # and store them\n",
    "        output[\"{}_{}\".format(target.split(\".\")[0], method)] = accuracy\n",
    "        non_adv_output[\"{}_{}\".format(target.split(\".\")[0], method)] = non_adv_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
