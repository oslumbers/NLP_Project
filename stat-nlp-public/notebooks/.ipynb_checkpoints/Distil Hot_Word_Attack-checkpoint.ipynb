{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from transformers import (DistilBertForSequenceClassification, \n",
    "                          DistilBertTokenizer)\n",
    "\n",
    "# Our code imports\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', 'src'))\n",
    "import train_eval\n",
    "import synonym\n",
    "\n",
    "importlib.reload(synonym)\n",
    "importlib.reload(train_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"imdb_distil.model\"\n",
    "pretrained_weights = 'distilbert-base-cased'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(pretrained_weights)\n",
    "max_seq = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = train_eval.ReviewDataset(source=\"imdb\")\n",
    "test_sentences, test_labels = imdb.reviewsAndLabels(test_train=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Hotwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_attacks = synonym.SynonymAttacks(model_path, tokenizer, 256)\n",
    "\n",
    "hws = []\n",
    "softmax_changes = []\n",
    "\n",
    "for hw, sm in s_attacks.generateHotWords(test_sentences, test_labels, train_no=25000, \n",
    "                                         method=\"blank\"):\n",
    "    hws.append(hw)\n",
    "    softmax_changes.append(sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save output\n",
    "# pickle.dump([hws, softmax_changes], open(\"distil_hw_sm.p\", \"wb\"))\n",
    "\n",
    "# Load output\n",
    "hw_sm = pickle.load(open('distil_hw_sm.p', 'rb'))\n",
    "hws = hw_sm[0]\n",
    "softmax_changes = hw_sm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_words = np.array([item for hw in hws for item in hw])\n",
    "diffs = [item for sm in softmax_changes for item in sm]\n",
    "vocab = list(set(hot_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_weights = []\n",
    "hot_words_encoding = np.array(tokenizer.encode(list(hot_words)))\n",
    "vocab_encoding = tokenizer.encode(vocab)\n",
    "\n",
    "for word in vocab_encoding[1:-1]:\n",
    "    word_weights.append(np.nanmean(np.where(hot_words_encoding[1:-1] == word, diffs, np.nan)))\n",
    "\n",
    "# Positive weight means it was made more positive - negative weight means it was made more negative\n",
    "word_weights = np.array(word_weights)\n",
    "word_weights_z = (word_weights - np.mean(word_weights)) / np.nanstd(word_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sorts = np.argsort(word_weights_z)\n",
    "ranked_words = np.array(vocab)[word_sorts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output\n",
    "# pickle.dump((vocab, word_weights_z, word_sorts), open(\"distil-vcb_wt_sort.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hot Words - Gamma Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From our previously calculated hot words\n",
    "vocab, word_weights, word_sorts = pickle.load(open(\"distil-vcb_wt_sort.p\", \"rb\"))\n",
    "word_dist = dict(zip(vocab, word_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['imdb']\n",
    "gammas = [0, 10, 20, 30, 40, 50, 60, 80, 100, 120]\n",
    "overall_acc = dict()\n",
    "    \n",
    "for dataset in datasets:\n",
    "    model_path = \"{}_distil.model\".format(dataset)\n",
    "    pretrained_weights = 'distilbert-base-cased'\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(pretrained_weights)\n",
    "\n",
    "    model = torch.load(model_path)\n",
    "\n",
    "    imdb = train_eval.ReviewDataset(source=dataset)\n",
    "    test_sentences, test_labels = imdb.reviewsAndLabels(test_train=\"test\")\n",
    "\n",
    "    # Instantiate attack class\n",
    "    s_attacks = synonym.SynonymAttacks(model_path, tokenizer, 256)\n",
    "    \n",
    "    accuracies = []\n",
    "    # Create adversarial examples\n",
    "    for gamma in gammas:\n",
    "        adv_data, adv_label = s_attacks.generateSynonymReviews(test_sentences, test_labels,\n",
    "                                                              replacements=gamma, \n",
    "                                                               hot_word_distribution=word_dist,\n",
    "                                                              method=\"random\")\n",
    "\n",
    "        evaluation_data, _ = train_eval.ReviewDataset.setUpData(adv_data, \n",
    "                                                               adv_label, \n",
    "                                                               tokenizer, 256)\n",
    "\n",
    "        acc = train_eval.evaluate(model, evaluation_data, 128)\n",
    "        acc = np.mean(acc[0])\n",
    "        print(\"for gamma = {}, accuracy: {}\".format(gamma, acc))\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    overall_acc[dataset] = accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
