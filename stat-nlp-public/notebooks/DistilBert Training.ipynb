{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from transformers import (DistilBertForSequenceClassification, \n",
    "                          DistilBertTokenizer)\n",
    "\n",
    "# Our code imports\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', 'src'))\n",
    "import train_eval\n",
    "import synonym\n",
    "\n",
    "importlib.reload(synonym)\n",
    "importlib.reload(train_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"imdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "imdb = train_eval.ReviewDataset(source=DATASET)\n",
    "train_sentences, train_labels = imdb.reviewsAndLabels(test_train=\"train\")\n",
    "\n",
    "# Set up model\n",
    "pretrained_weights = 'distilbert-base-cased'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(pretrained_weights)\n",
    "model_class = DistilBertForSequenceClassification\n",
    "model = model_class.from_pretrained(pretrained_weights, num_labels=2,\n",
    "                                   output_attentions = True,\n",
    "                                   output_hidden_states = False)\n",
    "train_data, validation_data = train_eval.ReviewDataset.setUpData(train_sentences, \n",
    "                                                           train_labels, \n",
    "                                                           tokenizer, 256, 0.2)\n",
    "\n",
    "# Print first and last example!\n",
    "for label, sent in zip(train_labels[[0, -1]], train_sentences[[0, -1]]):\n",
    "    print(\"label: {}\".format(label))\n",
    "    print(sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "losses, model = train_eval.train(model, \n",
    "                                 train_data, \n",
    "                                 validation_data, \n",
    "                                 batch_size=8, \n",
    "                                 epochs=1, \n",
    "                                 lr=3e-5, # from https://github.com/nshepperd/gpt-2/blob/finetuning/train.py\n",
    "                                 adam_eps=1e-8)\n",
    "\n",
    "# torch.save(model, '{}_distil.model'.format(DATASET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['imdb', 'yelp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "pretrained_weights = 'distilbert-base-cased'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(pretrained_weights)\n",
    "\n",
    "for d in datasets:\n",
    "\n",
    "    # Set up test data\n",
    "    imdb = train_eval.ReviewDataset(source=d)\n",
    "    test_sentences, test_labels = imdb.reviewsAndLabels(test_train=\"test\")\n",
    "\n",
    "    evaluation_data, _ = train_eval.ReviewDataset.setUpData(test_sentences, \n",
    "                                                               test_labels, \n",
    "                                                               tokenizer, 256)\n",
    "    model = torch.load('{}_distil.model'.format(d))\n",
    "    \n",
    "    # evaluate\n",
    "    acc = train_eval.evaluate(model, evaluation_data, 128)\n",
    "    print(\"{} accuracy: {}\".format(d, np.mean(acc[0])))\n",
    "    accuracies.append(np.mean(acc[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
